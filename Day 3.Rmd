---
title: "NTM Workshop Day 3"
author: "Rachel Mercaldo"
date: "2025-07-20"
output: html_document
---


#    Agenda

09:00 - 10:30    Review of Day 2
11:00 - 12:30    Spatiotemporal variable selection
13:30 - 15:30    Final models, using select variables
16:00            Daily review




##   Review of Day 2

On day 2, we covered an introduction to Weather Source data structure and primarily worked on merging Weather Source data files.
We got into a little bit of exploratory data analysis, and learned about some core spatiotemporal epidemiology methods.

Below is Rachel's version of the code from Day 2. Run through it and complete the (revised) exercises to practice!


###  To begin, make sure you have saved this file and opened it from the same folder as the Weather Source data.


Here is a test code chunk. Run it. See where the results print (right below the code chunk). Convenient!

```{r}
#This an R code chunk!

print('hello')

3+3

x <- 3 + 3

x*2

```


### Let's review Day 2 now. First, we need to load our libraries

```{r}

library(dplyr)
library(stringr)
library(data.table)

```


### Next, we will load the data. 

As we discussed yesterday, there are numerous meteorology files. We will first use the list.files() function to loop over all the files in the NTM Workshop folder where you have saved the data (your working directory) and list the ones that have the words "meteorology" in the filename. Then, the lapply() function will take that list of files, read them using read.csv() and then pipe them ( using %>% ) to the bind_rows() function.
The result is a single data set that has all the meteorology data. 
You can think of bind_rows() as stacking the different datasets on top of each other. This only works if every file has the same columns/column names. Thanksfully, our files do. :)

```{r}

file_names <- list.files(pattern = "meteorology") 
met<- lapply(file_names, read.csv) %>% bind_rows()

```


Thankfully, it is easier to read in the land use and air quality data:

```{r}

#air quality
air <- read.csv("air_quality.csv")

#land use
land <- read.csv("land_use.csv")

```


Today, we are going to aggregate all our data separately, before merging it. This way, we can ensure that everything is looking good at the monthly level before we join it all together.

```{r}

#meteorology:
met$year_month <- paste(substr(met$date_valid_std, 6,7), substr(met$date_valid_std, 1, 4),sep = "/")

 
#overall
met1 <- aggregate(met[,c(3:4,7:51,55:61)], list(met$fips, met$year_month), mean) #all variables except 
met2 <- aggregate(met[,c(52:54)], list(met$fips, met$year_month), sum) #precipitation should be total
  

